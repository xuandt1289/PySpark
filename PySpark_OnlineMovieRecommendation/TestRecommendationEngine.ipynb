{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5695e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine.py\n",
    "import os\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    \"\"\"Given a tuple (movieID, ratings_iterable) \n",
    "    returns (movieID, (ratings_count, ratings_avg))\n",
    "    \"\"\"\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "\n",
    "class RecommendationEngine:\n",
    "    \"\"\"A movie recommendation engine\n",
    "    \"\"\"\n",
    "\n",
    "    def __count_and_average_ratings(self):\n",
    "        \"\"\"Updates the movies ratings counts from \n",
    "        the current data self.ratings_RDD\n",
    "        \"\"\"\n",
    "        logger.info(\"Counting movie ratings...\")\n",
    "        movie_ID_with_ratings_RDD = self.ratings_RDD.map(lambda x: (x[1], x[2])).groupByKey()\n",
    "        movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "        self.movies_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n",
    "\n",
    "    def __train_model(self, sc):\n",
    "        \"\"\"Train the ALS model with the current dataset\n",
    "        \"\"\"\n",
    "        # load the trained model\n",
    "        logger.info(\"Loading the ALS model...\")\n",
    "        model_path = os.path.join('models', 'movie_lens_als')\n",
    "        self.model = MatrixFactorizationModel.load(sc, model_path)\n",
    "        logger.info(\"ALS model is loaded successfully!\")\n",
    "\n",
    "\n",
    "    def __predict_ratings(self, user_and_movie_RDD):\n",
    "        \"\"\"Gets predictions for a given (userID, movieID) formatted RDD\n",
    "        Returns: an RDD with format (movieTitle, movieRating, numRatings)\n",
    "        \"\"\"\n",
    "        predicted_RDD = self.model.predictAll(user_and_movie_RDD)\n",
    "        predicted_rating_RDD = predicted_RDD.map(lambda x: (x.product, x.rating))\n",
    "        predicted_rating_title_and_count_RDD = predicted_rating_RDD.join(self.movies_titles_RDD).join(self.movies_rating_counts_RDD)\n",
    "        predicted_rating_title_and_count_RDD = predicted_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "        \n",
    "        return predicted_rating_title_and_count_RDD\n",
    "    \n",
    "    def add_ratings(self, ratings):\n",
    "        \"\"\"Add additional movie ratings in the format (user_id, movie_id, rating)\n",
    "        \"\"\"\n",
    "        # Convert ratings to an RDD\n",
    "        new_ratings_RDD = self.sc.parallelize(ratings)\n",
    "        # Add new ratings to the existing ones\n",
    "        self.ratings_RDD = self.ratings_RDD.union(new_ratings_RDD)\n",
    "        # Re-compute movie ratings count\n",
    "        self.__count_and_average_ratings()\n",
    "        # Re-train the ALS model with the new ratings\n",
    "        self.__train_model()\n",
    "        \n",
    "        return ratings\n",
    "\n",
    "    def get_ratings_for_movie_ids(self, user_id, movie_ids):\n",
    "        \"\"\"Given a user_id and a list of movie_ids, predict ratings for them \n",
    "        \"\"\"\n",
    "        requested_movies_RDD = self.sc.parallelize(movie_ids).map(lambda x: (user_id, x))\n",
    "        # Get predicted ratings\n",
    "        ratings = self.__predict_ratings(requested_movies_RDD).collect()\n",
    "\n",
    "        return ratings\n",
    "    \n",
    "    def get_top_ratings(self, user_id, movies_count):\n",
    "        \"\"\"Recommends up to movies_count top unrated movies to user_id\n",
    "        \"\"\"\n",
    "        # Get pairs of (userID, movieID) for user_id unrated movies\n",
    "        user_unrated_movies_RDD = self.ratings_RDD.filter(lambda rating: not rating[0] == user_id).map(lambda x: (user_id, x[1])).distinct()\n",
    "        # Get predicted ratings\n",
    "        ratings = self.__predict_ratings(user_unrated_movies_RDD).filter(lambda r: r[2]>=25).takeOrdered(movies_count, key=lambda x: -x[1])\n",
    "\n",
    "        return ratings\n",
    "\n",
    "    def __init__(self, sc, dataset_path):\n",
    "        \"\"\"Init the recommendation engine given a Spark context and a dataset path\n",
    "        \"\"\"\n",
    "\n",
    "        logger.info(\"Starting up the Recommendation Engine: \")\n",
    "\n",
    "        self.sc = sc\n",
    "\n",
    "        # Load ratings data for later use\n",
    "        logger.info(\"Loading Ratings data...\")\n",
    "        ratings_file_path = os.path.join(dataset_path, 'ratings.csv')\n",
    "        ratings_raw_RDD = self.sc.textFile(ratings_file_path)\n",
    "        ratings_raw_data_header = ratings_raw_RDD.take(1)[0]\n",
    "        self.ratings_RDD = ratings_raw_RDD.filter(lambda line: line!=ratings_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "\n",
    "        # Load movies data for later use\n",
    "        logger.info(\"Loading Movies data...\")\n",
    "        movies_file_path = os.path.join(dataset_path, 'movies.csv')\n",
    "        movies_raw_RDD = self.sc.textFile(movies_file_path)\n",
    "        movies_raw_data_header = movies_raw_RDD.take(1)[0]\n",
    "        self.movies_RDD = movies_raw_RDD.filter(lambda line: line!=movies_raw_data_header).map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "        self.movies_titles_RDD = self.movies_RDD.map(lambda x: (int(x[0]),x[1])).cache()\n",
    "        # Pre-calculate movies ratings counts\n",
    "        self.__count_and_average_ratings()\n",
    "\n",
    "        # Load the trained model\n",
    "        self.__train_model(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e3c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys, cherrypy, os\n",
    "from paste.translogger import TransLogger\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import psutil\n",
    "\n",
    "def init_spark_context():\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "\n",
    "    import pyspark\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    # load spark context\n",
    "    conf = SparkConf().setAppName(\"movie_recommendation-server\")\n",
    "    # IMPORTANT: pass additional Python modules to each worker\n",
    "    sc = SparkContext(conf=conf)\n",
    "\n",
    "    return sc\n",
    "\n",
    "\n",
    "# Init spark context and load libraries\n",
    "sc = init_spark_context()\n",
    "dataset_path = os.path.join('datasets', 'ml-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e434de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting up the Recommendation Engine: \n",
      "INFO:__main__:Loading Ratings data...\n",
      "INFO:__main__:Loading Movies data...\n",
      "INFO:__main__:Counting movie ratings...\n",
      "INFO:__main__:Loading the ALS model...\n",
      "INFO:__main__:ALS model is loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "global recommendation_engine \n",
    "recommendation_engine = RecommendationEngine(sc, dataset_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e1a37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Toy Story (1995)', 4.762946226604339, 68469)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 1\n",
    "movie_id = 1\n",
    "ratings = recommendation_engine.get_ratings_for_movie_ids(user_id, [movie_id])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bd6deb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('On the Beach (1959)', 6.0661263219117485, 624),\n",
       " ('Lady Jane (1986)', 5.996498996763119, 286),\n",
       " (\"Adam's Rib (1949)\", 5.996498996763119, 1108),\n",
       " ('Crossing Delancey (1988)', 5.996498996763119, 590),\n",
       " ('Shall We Dance (1937)', 5.96536807496949, 1519)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 5\n",
    "top_ratings = recommendation_engine.get_top_ratings(user_id,count)\n",
    "top_ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
